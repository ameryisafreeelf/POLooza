{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw          # Python Reddit API wrapper- pip install if you don't have it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This creates a Reddit instance\n",
    "reddit = praw.Reddit(client_id = 'kCjbiHmfa6QCHg', \n",
    "                     client_secret = 'oE4G_WsYBcQUGyWGndq1tJ5Qnzw', \n",
    "                     # Put password below\n",
    "                     # password = PUT THE PASSWORD HERE \n",
    "                     password = 'CrainChangChangCrain',\n",
    "                     user_agent = 'myAgent', \n",
    "                     # Put the username below\n",
    "                     # username = USERNAME HERE\n",
    "                     username = 'BootyMcBootyson'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BootyMcBootyson\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes a list of strings\n",
    "# Returns a list of subreddit objects\n",
    "def get_subreddits(subreddit_names):\n",
    "    subreddit_list = []\n",
    "    for i in subreddit_names:\n",
    "        sr = reddit.subreddit(i)\n",
    "        subreddit_list.append(sr)\n",
    "    return subreddit_list\n",
    "\n",
    "# Takes a single submission object\n",
    "# Returns dictionary of k = submission id, v = list of features\n",
    "def parse_comments(submission):\n",
    "    comments_dict = {}\n",
    "    # Get past the \"more comment\" object to extract all comments\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    # Get all comments as flattened list\n",
    "    comments = submission.comments.list()    \n",
    "    for comment in comments:\n",
    "        comments_dict[comment.id] = [str(comment.body), str(comment.subreddit), comment.score, comment.created_utc, \n",
    "                                     'comment']\n",
    "    return comments_dict\n",
    "\n",
    "# For posts, one approach might be to just take the title of the post\n",
    "# This is because post bodies (\"selftext\") may just be links or images\n",
    "# Takes a list of subreddit objects and extracts comments and posts\n",
    "# Returns dictionary of k = submission id, v = list of features\n",
    "def parse_top_posts(subreddits):\n",
    "    content_dict = {}\n",
    "    for i in subreddits:\n",
    "        for submission in i.top(time_filter='all', limit = 50):\n",
    "            # Add an entry to posts_dict where value is a list of features\n",
    "            content_dict[submission.id] = [str(submission.title), str(submission.subreddit), submission.score, \n",
    "                                           submission.created_utc, 'post']\n",
    "            # Now extract comments\n",
    "            comments_dict_buff = parse_comments(submission)\n",
    "            content_dict.update(comments_dict_buff)\n",
    "    return content_dict\n",
    "\n",
    "# This is a wrapper method that calls the others\n",
    "# Takes a list of names of subreddits\n",
    "# Returns a dataframe of posts and features\n",
    "def create_reddit_dataset(subreddit_names_list):\n",
    "    subreddits = get_subreddits(subreddit_names_list)\n",
    "    content_dict = parse_top_posts(subreddits)\n",
    "    col_names = ['text', 'subreddit', 'score', 'time', 'content_type']\n",
    "    df = pd.DataFrame.from_dict(content_dict, orient='index', columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sub_names = [\"news\", \n",
    "                \"politics\", \n",
    "                \"worldnews\", \n",
    "                \"PoliticalHumor\", \n",
    "                \"worldpolitics\", \n",
    "                \"Economics\", \n",
    "                \"PoliticalDiscussion\"\n",
    "                \"TheDonald\",\n",
    "                \"LateStageCapitalism\",\n",
    "                \"Libertarian\",\n",
    "                \"SandersForPresident\", \n",
    "                \"conservative\",\n",
    "                \"socialism\",\n",
    "                \"bluemidterm2018\",\n",
    "                \"democrats\",\n",
    "                \"anarcho_capitalism\",\n",
    "                \"Liberal\"\n",
    "                \"progressive\"\n",
    "                \"neoliberal\"\n",
    "                ]\n",
    "\n",
    "my_out_names = [\"news.csv\",\n",
    "                \"politics.csv\",\n",
    "                \"worldnews.csv\",\n",
    "                \"PoliticalHumor.csv\", \n",
    "                \"worldpolitics.csv\", \n",
    "                \"Economics.csv\", \n",
    "                \"PoliticalDiscussio.csv\"\n",
    "                \"TheDonald.csv\",\n",
    "                \"LateStageCapitalism.csv\",\n",
    "                \"Libertarian.csv\",\n",
    "                \"SandersForPresident.csv\", \n",
    "                \"conservative.csv\",\n",
    "                \"socialism.csv\",\n",
    "                \"bluemidterm2018.csv\",\n",
    "                \"democrats.csv\",\n",
    "                \"anarcho_capitalism.csv\",\n",
    "                \"Liberal.csv\"\n",
    "                \"progressive.csv\"\n",
    "                \"neoliberal.csv\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kept getting a 400 error that I don't understand, which I resolved by simply pulling by subreddit \n",
    "annoying, but it worked)\n",
    "\"\"\"\n",
    "\n",
    "index = 0\n",
    "\n",
    "my_list = [\"neoliberal\"]\n",
    "\n",
    "my_data = create_reddit_dataset(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data.to_csv(\"neoliberal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economics.csv              bluemidterm2018.csv\r\n",
      "LateStageCapitalism.csv    conservative.csv\r\n",
      "Liberal.csv                democrats.csv\r\n",
      "Libertarian.csv            neoliberal.csv\r\n",
      "PoliticalDiscussion.csv    news.csv\r\n",
      "PoliticalHumor.csv         politics.csv\r\n",
      "RedditAPITesting.ipynb     progressive.csv\r\n",
      "RedditDataCollection.ipynb reddit.csv\r\n",
      "SandersForPresident.csv    socialism.csv\r\n",
      "TheDonald.csv              worldnews.csv\r\n",
      "anarcho_capitalism.csv     worldpolitics.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4945, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'subreddit', 'score', 'time', 'content_type'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "translate() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7566e9be2d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mline_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdoc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: translate() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from string import punctuation\n",
    "\n",
    "for line in my_data.columns:\n",
    "    line = line.translate(None, punctuation).strip('\\t')\n",
    "    line_contents = line.split(\" \")\n",
    "    doc_name = line_contents[0]\n",
    "    line_contents.remove(doc_name)\n",
    "    for content in line_contents:\n",
    "      content = content.rstrip()\n",
    "      key = content + \",\" + doc_name\n",
    "      print( '%s\\t%s' % (key, 1) )                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As a reminder, this subreddit [is for civil discussion.](/r/politics/wiki/index#wiki_be_civil)\n",
      "\n",
      "In general, be courteous to others. Attack ideas, not users. Personal insults, shill or troll accusations, hate speech, **any** advocating or wishing death/physical harm, and other rule violations can result in a permanent ban. \n",
      "\n",
      "If you see comments in violation of our rules, please report them.\n",
      "\n",
      "***\n",
      "\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*\n",
      "\n",
      "Good job Kentucky! \n",
      "\n",
      "title should be: \"Lady who refused to do job, loses job.\"\n",
      "\n",
      "From what I remember, this awful bitch owes the people of Kentucky some goddamn money... And human beings, in general, an apology\n",
      "\n",
      "Guess it was God's will ¯\\\\\\_(ツ)\\_/¯\n",
      "\n",
      "Good, now she can go back to husband number, what was it, four?\n",
      "\n",
      "700 votes. Remember every vote matters.\n",
      "\n",
      "It appears that an all powerful god rejected her.\n",
      "\n",
      "Thoughts and prayers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(my_data.text.values[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just load the csv to Dumbo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
